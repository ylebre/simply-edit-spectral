<!DOCTYPE HTML>
<html>
	<head>
		<title>Mayur Bhise::Portfolio Website</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<link rel="icon" href="images/favicon.ico">
	</head>
	<body>

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="index.html">Mayur Bhise</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
									<a href="#menu" class="menuToggle"><span>Menu</span></a>
									<div id="menu">
										<ul>
											<li><a href="index.html">Home</a></li>
											<li><a href="index.html#projects">Projects</a></li>
											<li><a href="index.html#about">About</a></li>
											<li><a href="index.html#contact">Contact</a></li>
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<article id="main">
						<header>
							<h2>Computer Vision &amp; AI for Robotics</h2>
						</header>
						<section class="wrapper style5">
							<div class="inner">

								<h3>Projects Overview</h3>

								<p>The following projects were completed as a part of the my Research and Review at Northeastern Robotics, explores different aspects of computer vision applications required in a real self driving car, to ensure a deep understanding of the working of the various components involved within. See below for an overview of some of the projects!</p>

								<hr />

								<h3 align="left">Skills Involved</h3>
								<ul>
									<li align="left">Deep Learning</li>
									<li align="left">Programming in Python</li>
									<li align="left">Convolutional Neural Networks</li>
									<li align="left">Data/Image Processing</li>
									<li align="left">Transformers</li>
									<li align="left">Transfer Learning</li>
                  							<li align="left">Data Augmentation</li>
									<li align="left">Machine Learning development, setup, training, and implementation</li>
									<li align="left">Linear Algebra and Differential Calculus</li>
								</ul>

              							  <hr />

								<div class="row">
									<div class="6u 12u$(medium)">
										<span class="image fit"><img src="images/segformers.gif" alt="Full Frame Segmentation Using Segformers" /></span>
									</div>
									<div class="6u$ 12u$(medium)">
										<h3>Full Frame Segmentation using SegFormers</h3>
										<p>This Project involved developing a Full Frame segmentation module using Vision Transformers, based on the paper <a href="https://arxiv.org/abs/2105.15203">Segformer: Simple and Efficient Design for Semantic Segmentation with Transformers</a>, Transformers have multiple attention heads, in contrast to CNN based architecture, which concentrate on local attention, these multiple heads in various stages pay attention to every region in the image, as seen from the attention maps, and the mIoU is also far better than with previous approaches </p>

									  <p>Segformers is a very revolutionary algorithm in the field of segmentation, here is the link to my medium blog, if you'd like to learn more about the components and working of the algorithm</p>
										<p>Get the code <b><a href="https://github.com/mayB1998/Computer Vision/tree/main/Segmentation" target="blank" > here</a></b>.</p>

									</div>
								</div>

								
              							  <hr />

								<div class="row">
									<div class="6u 12u$(medium)">
										<span class="image fit"><img src="images/segmentation.gif" alt="Drivable area Segmentation using CNNs" /></span>
									</div>
									<div class="6u$ 12u$(medium)">
										<h3>Semantic Segmentation using UNET and DeepLab V3+</h3>
										<p>The project was centered on the development and comparison of an "online" variant of the U-Net and Deeplab V3+ semantic segmentation algorithm, tailored to a subset of the BDD100K dataset. The primary challenge revolved around designing an optimized U-Net architecture and fine-tuning the model for real-time, on-the-fly segmentation of incoming images. This involved carefully crafting the encoder-decoder structure and selecting appropriate skip connections. Additionally, the project incorporated the formulation of a specialized loss function, data augmentation techniques, and post-processing methods to enhance the segmentation quality. The system's performance was evaluated using metrics like Intersection over Union (IoU) to ensure accurate object delineation. Ultimately, the online U-Net segmentation was integrated with an Inverse Kinematic (IK) motion controller, further extending its capabilities for real-time object tracking and navigation.</p>

									  <p>In the final stages of the project, significant effort was dedicated to fine-tuning the IK motion controller to account for dynamic factors such as maximum velocity and acceleration constraints. This ensured that the system could effectively guide a robot or agent within the segmented regions, facilitating precise and responsive motion. The project's successful outcome demonstrated the feasibility of real-time semantic segmentation on a specific dataset subset and its integration with motion control, opening up opportunities for applications in robotics, autonomous navigation, and computer vision tasks.</p>
										<p>Get the code <b><a href="https://github.com/mayB1998/DeeplabV3-Autonomous_Driving" target="blank" > here</a></b>.</p>

									</div>
								</div>

								<hr />
                						<div class="row">
									<div class="6u 12u$(medium)">
										<span class="image fit"><img src="images/depth_mapping.gif" alt="Depth Mapping" /></span>
									</div>
									<div class="6u$ 12u$(medium)">
										<h3>Object Detection and Depth Mapping</h3>
										<p>Camera is the most reliable sensor for Perception and Computer Vision, and with it we can, get a sufficient understanding to navigate through the environment, in this project we will discuss how we can perform mutiple perception tasks through the stereo camera, if we calibrate the cameras accurately and have good weather conditions, we can get near perfect measurements from the sensor, which reduces the dependency on other sensors, lets discuss what are the steps involved in the project</p>

									  <p>The Project starts with collecting Data from the camera, I have also collected data from my oak-D stero camera, for this purpose, for all computer vision tasks the camera needs to be calibrated, after that we import the images, and recify them if any distortion is still present, and calculate disparity in the image, which is basically difference in Pixel brightness, and with some linear algebra magic, we are able to calculate projection matrix which helps us in depth mapping, and using yolo v4(object detection library) we can put the objects in bouding boxes, and we can add distances to the bounding boxes, which we aquire form the depth mapping, thus creating a robust computer vision pipeline, which can be further enhanced to include 3d reconstruction </p>
										<p>Get the code <b><a href="https://github.com/mayB1998/Self-Driving-Car-Algorithms/tree/main/CarND-Traffic-Sign-Classifier-Project" target="blank" > here</a></b>.</p>

									</div>
								</div>

								<hr />
                						<div class="row">
									<div class="6u 12u$(medium)">
										<span class="image fit"><img src="images/sfm.png" alt="Structure for Motion" /></span>
									</div>
									<div class="6u$ 12u$(medium)">
										<h3>Incremental Structure for Motion</h3>
										<p>Structure for Motion (SfM) pipeline for generating sparse point clouds using SIFT feature tracking. This pipeline uses the SIFT algorithm for feature tracking, followed by essential matrix estimation, pose recovery, triangulation, and bundle adjustment for optimizing the point cloud.</p>

									  <p>In my incremental Structure from Motion (SfM) project, I aim to develop a robust and efficient system for reconstructing three-dimensional scenes from a sequence of images. By incrementally processing each frame, I plan to enhance the scalability and real-time performance of the SfM pipeline. The project will involve feature extraction, matching, and camera pose estimation in a step-by-step manner, gradually building a more accurate and complete model of the scene. Leveraging keyframes and optimizing the structure incrementally will contribute to better handling large datasets and dynamic scenes. The incremental approach not only improves the overall accuracy of the reconstructed 3D models but also ensures adaptability to changing environments, making it suitable for various applications such as augmented reality, robotics, and virtual reality.</p>
										<p>Get the code <b><a href="https://github.com/mayB1998/computer-vision" target="blank" > here</a></b>.</p>

									</div>
								</div>
								
								<hr />

								<div class="row">
									<div class="6u 12u$(medium)">
										<span class="image fit"><img src="images/trafficsignclassifier.jpg" alt="Traffic Sign Classifier" /></span>
									</div>
									<div class="6u$ 12u$(medium)">
										<h3>Traffic Sign Classifier</h3>
										<p>Traffic Sign Classification is a fundamental issue that a self driving car should be able to distinguish, the signs should be accurately classified in order to avoid unexpected scenarios during control</p>

									  <p>in this classifier the German Traffic Sign Dataset was used with 25k images trained on LeNet, the architecture devised by Yaan Le Cun for document classification, I tested the network on VGG16 as it was iterated upon the existing networks and which won the IMAGEnet challenge in 2015</p>
										<p>Get the code <b><a href="https://github.com/mayB1998/Self-Driving-Car-Algorithms/tree/main/CarND-Traffic-Sign-Classifier-Project" target="blank" > here</a></b>.</p>

									</div>
								</div>


				

								<hr />

								<div class="row">
									<div class="6u 12u$(medium)">
										<h3> Lane Finding</h3>
										<p>This Project involves python and OpenCV to develop an analytical pipeline that can be ued to automate the lane line detection in image and movie files</p>

										<p>The project was structured accordingly :Building the Vision Pipeline consisting of gaussian blurring, defining areas of interest, graysacling to detect sharp transitions, along with canny edge detection, to detect patterns, features in an image by thresholding the pisel densities, along with Hough line transfrom to accurately mask the areas of interest, the model was then tested on both images and a set of videos with frames at 30 fps, with a industry standard accuracy</p>

										<p>Get the code <b><a href="https://github.com/mayB1998/Self-Driving-Car-Algorithms/tree/main/CarND-LaneFinding" target="blank" > here</a></b>.</p>

									</div>
									<div class="6u$ 12u$(medium)">
										<span class="image fit"><img src="images/lanefind.jpg" alt="Comparison of the different dead-reckoning methods" /></span>
									</div>
								</div>

								<hr />

								<h3>Learn More</h3>

								<p></p>
							</div>
						</section>
					</article>


				<!-- Footer -->
					<footer id="footer">
						<ul class="icons">
							<li><a href="https://github.com/mayb1998/" target="blank" class="icon fa-github fa-lg"><span class="label">Github</span></a></li>
							<li><a href="https://www.linkedin.com/in/mayur-bhise" target="blank" class="icon fa-linkedin fa-lg"><span class="label">Email</span></a></li>
							<li><a href="mailto:bhise.m@northeastern.edu" class="icon fa-envelope-o fa-lg"><span class="label">Email</span></a></li>
						</ul>
						<ul class="copyright">
							<li>Template: <a href="https://html5up.net/spectral"> SPECTRAL</a></li><li>From: <a href="http://html5up.net">HTML5 UP</a></li>						</ul>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
